{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga imagen y convierte a RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga imagen ejemplo con monedas\n",
    "img = cv2.imread('Monedas.jpg') \n",
    "print(img.shape)\n",
    "#Recordar que OpenCV lee las imágenes en BGR, por lo que convertimos para visualizr a RGB\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_rgb) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convierte a gris y muestra histograma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convierte la imagen a todos de gris, mostrando el resultado\n",
    "img_gris = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Cálculo del histograma con 256 bins de una imagen en escala de grises\n",
    "hist = cv2.calcHist([img_gris], [0], None, [256], [0, 256])\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_gris, cmap='gray')\n",
    "\n",
    "# Histograma sin normalizar\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Histograma\")\n",
    "plt.xlabel(\"Bins\")\n",
    "plt.ylabel(\"# píxeles\")\n",
    "plt.plot(hist)\n",
    "plt.xlim([0, 256])\n",
    "# Separo subplots horizontalmente\n",
    "plt.subplots_adjust(wspace=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuenta elementos tras umbralizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dos variantes de umbralizado. Probar otros parámetros, aplicar filtro previo, etc.\n",
    "umbral = 200 # Prueba varios comenzando en 130\n",
    "# Umbralizado binario invertido, dado que por defecto se asume objetos en blanco\n",
    "th1,img_th1 = cv2.threshold(img_gris,umbral,255,cv2.THRESH_BINARY_INV)\n",
    "print('Umbral fijo usado ', th1)\n",
    "# Umbralizado con método de Otsu para selección automática del umbral\n",
    "th2,img_th2 = cv2.threshold(img_gris,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "print('Umbral Otsu ', th2)\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_gris,cmap='gray') \n",
    "plt.title('Original')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_th1,cmap='gray') \n",
    "plt.title('FIJO invertida')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_th2,cmap='gray') \n",
    "plt.title('OTSU invertida')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Búsqueda de componentes y sus contornos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Localiza contornos en imagen obtenida con umbral fijo\n",
    "#findContours está diseñada para imágenes con  figura en blanco y fondo negro\n",
    "#La imagen de entrada debe ser de un canal y 8 bits excepto en los modos RETR_CCOMP o RETR_FLOODFILL\n",
    "#hierarchy contiene información sobre el nivel del contorno, relaciones paterno-filiales (contornos contenidos en otros)\n",
    "\n",
    "#Obtiene todos los contornos: externos e internos\n",
    "contornos, hierarchy = cv2.findContours(\n",
    "    img_th1, #imagen\n",
    "    cv2.RETR_TREE, #Modo de recuperación (lista, árbol, nivel superior)\n",
    "    cv2.CHAIN_APPROX_SIMPLE #Método de aproximación del contorno\n",
    "    )\n",
    "\n",
    "#Dibuja sobre la imagen de entrada los contornos en verde\n",
    "#Cada vez que quiere pintar convierte img para no tener restos\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "cv2.drawContours(img_rgb, contornos, -1, (0,255,0), 3)\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_rgb) \n",
    "plt.title('Todos los contornos')\n",
    "\n",
    "#Obtiene únicamente los contornos externos\n",
    "contornos2, hierarchy2 = cv2.findContours(img_th1, \n",
    "    cv2.RETR_EXTERNAL , \n",
    "    cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#Dibuja sobre la imagen de entrada sólo contornos externos\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "cv2.drawContours(img_rgb, contornos2, -1, (0,255,0), 3)\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_rgb) \n",
    "plt.title('Externos')\n",
    "\n",
    "#Dibuja contornos externos rellenos en imagen vacía\n",
    "#Imagen negra\n",
    "img_cont = np.zeros(img_rgb.shape)\n",
    "#Recorre los contornos externos\n",
    "for c in contornos2:\n",
    "    #Área del contorno\n",
    "    area = cv2.contourArea(c)\n",
    "    #Área mínima (útil filtrar en ocasiones)\n",
    "    if area > 10:\n",
    "        #Perímetro del contorno\n",
    "        perimetro = cv2.arcLength(c,True)\n",
    "        #Contenedor alineado con ejes de la imagen\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        #Mínimo contenedor ajustado para el contorno\n",
    "        rect = cv2.minAreaRect(c)\n",
    "        #Mínimo círculo que contiene al contorno\n",
    "        (cx,cy),radio = cv2.minEnclosingCircle(c)\n",
    "        #Elipse ajustada al contorno, exgigiendo un mínimo de puntos del contornos\n",
    "        if c.shape[0] > 5:\n",
    "            elipse = cv2.fitEllipse(c)\n",
    "            #Para determinadas tareas nos puede interesará mostrar los valores obtenidos del contorno\n",
    "            #print(area, perimetro, rect, cx,cy,radio, elipse)\n",
    "\n",
    "        #Dibuja los contornos\n",
    "        cv2.drawContours(img_cont, [c], -1, (255,255,255), -1)\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_cont) \n",
    "plt.title('Externos rellenos')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternativa contando círculos utilizando la Transformada de Hough. La selección de parámetros puede ser \"divertida\", más [información](https://docs.opencv.org/4.x/da/d53/tutorial_py_houghcircles.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conversión a gris\n",
    "gris = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "#Suaviza imagen (elimina altas frecuencias)\n",
    "pimg = cv2.medianBlur(gris, 7)\n",
    "#Localiza Círculos\n",
    "circ = cv2.HoughCircles(\n",
    "        pimg,  # imagen \n",
    "        cv2.HOUGH_GRADIENT,  # tipo de detección\n",
    "        1,\n",
    "        100,  # distancia mínima entre círculos\n",
    "        param1=100, # valor del gradiente\n",
    "        param2=50, # umbral acumulador\n",
    "        minRadius=50,  # radio mínimo\n",
    "        maxRadius=150,  # radio máximo\n",
    "    )\n",
    "\n",
    "#Dibuja sobre entrada e imagen vacía\n",
    "img_cont = np.zeros(img_rgb.shape)\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "for det in circ[0]:\n",
    "        x_coor, y_coor, det_radio = det\n",
    "        cv2.circle(img_rgb,(int(x_coor), int(y_coor)),\n",
    "            int(det_radio),(0, 255, 0), 2)\n",
    "        cv2.circle(img_cont,(int(x_coor), int(y_coor)),\n",
    "            int(det_radio),(255, 255, 255), -1)\n",
    "\n",
    "#Muestra resultado\n",
    "plt.subplot(121)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_rgb) \n",
    "plt.title('Círculos')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(img_cont) \n",
    "plt.title('Rellenos')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las formas localizadas tienen distintas características geométricas, que pueden estimarse a partir de sus contornos. Más infromatión en la [documentación de OpenCV](https://docs.opencv.org/4.x/dd/d49/tutorial_py_contour_features.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creación de polígono regular\n",
    "def poligono_regular(image, ctr, radio, lados, color):\n",
    "    pts = []\n",
    "    ang_step = 2 * np.pi / lados\n",
    "    for i in range(lados):\n",
    "        ang = i * ang_step\n",
    "        x = int(ctr[0] + radio * np.cos(ang))\n",
    "        y = int(ctr[1] + radio * np.sin(ang))\n",
    "        pts.append((x, y))\n",
    "    pts = np.array(pts, np.int32)\n",
    "    #regorganiza\n",
    "    pts = pts.reshape((-1, 1, 2))\n",
    "    cv2.fillPoly(image, [pts], color=color)\n",
    "\n",
    "# Imagen vacía\n",
    "img = np.zeros((400, 400, 1), dtype=\"uint8\")\n",
    "color = (255, 255, 255)\n",
    "\n",
    "# Formas básicas\n",
    "cv2.circle(img, (100, 100), 50, color, -1)  # Circular\n",
    "poligono_regular(img, (250, 150), 50, 5, color)  # Polígono regular\n",
    "cv2.ellipse(img, (200, 300), (100, 40), 0, 0, 360, color, -1)  # Elíptica\n",
    "\n",
    "# Localiza contornos\n",
    "contours, _ = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Parámeros texto\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 0.3\n",
    "thickness = 1\n",
    "\n",
    "# Process each contour to calculate compactness and ellipse ratio (if possible)\n",
    "for c in contours:\n",
    "    # Puntos del contorno\n",
    "    clon = len(c)\n",
    "\n",
    "    # Área y perímetro\n",
    "    area = cv2.contourArea(c)\n",
    "    perimetro = cv2.arcLength(c, True)\n",
    "\n",
    "    #Contenedor alineado con ejes de la imagen\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    \n",
    "    # Compactness: 4*pi*Area/Perimeter^2\n",
    "    if perimetro > 0:\n",
    "        compacidad = (perimetro ** 2) / area\n",
    "    else:\n",
    "        compactness = 0\n",
    "    \n",
    "    # Ajusta elipse si hay suficientes puntos\n",
    "    if clon >= 5:\n",
    "        elipse = cv2.fitEllipse(c)\n",
    "        (center, axes, orientation) = elipse\n",
    "        major_axis = max(axes)\n",
    "        minor_axis = min(axes)\n",
    "        elipse_ratio = major_axis / minor_axis\n",
    "    else:\n",
    "        elipse_ratio = None\n",
    "    \n",
    "    # Muestra valores en imageb\n",
    "    cv2.putText(img, f\"n: {clon:.1f}\", (x, int(y+h+10)), font, font_scale, (255, 255, 255), thickness)\n",
    "    cv2.putText(img, f\"A: {area:.1f}\", (x, int(y+h+20)), font, font_scale, (255, 255, 255), thickness)\n",
    "    cv2.putText(img, f\"P: {perimetro:.1f}\", (x, int(y+h+30)), font, font_scale, color, thickness)\n",
    "    cv2.putText(img, f\"C: {compacidad:.1f}\", (x, int(y+h+40)), font, font_scale, color, thickness)\n",
    "    cv2.putText(img, f\"ER: {elipse_ratio:.1f}\", (x, int(y+h+50)), font, font_scale, color, thickness)\n",
    "    \n",
    "# Visualiza la imagen\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Formas\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAREA: Captura una o varias imágenes con monedas no solapadas. Tras visualizar la imagen, identifica de forma interactiva (por ejemplo haciendo clic en la imagen) una moneda de un valor determinado en la imagen (por ejemplo de 1€). Tras ello, la tarea se resuelve mostrando por pantalla el número de monedas y la cantidad de dinero presentes en la imagen. No hay restricciones sobre utilizar medidas geométricas o de color. ¿Qué problemas han observado?\n",
    "\n",
    "Nota: Para establecer la correspondencia entre píxeles y milímetros, comentar que la moneda de un euro tiene un diámetro de 23.25 mm. la de 50 céntimos de 24.35, la de 20 céntimos de 22.25, etc. \n",
    "\n",
    "Extras: Considerar que la imagen pueda contener objetos que no son monedas y/o haya solape entre las monedas. Demo en vivo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moneda seleccionada como referencia (1 EUR)\n",
      "Relación píxeles/mm calculada: 6.1935\n",
      "Moneda identificada: 2 eur (Diámetro estimado: 26.16 mm)\n",
      "Moneda identificada: 50 cent (Diámetro estimado: 23.90 mm)\n",
      "Moneda identificada: 20 cent (Diámetro estimado: 22.28 mm)\n",
      "Moneda identificada: 5 cent (Diámetro estimado: 20.67 mm)\n",
      "Moneda identificada: 2 cent (Diámetro estimado: 18.73 mm)\n",
      "Moneda identificada: 1 eur (Diámetro estimado: 23.25 mm)\n",
      "Moneda identificada: 10 cent (Diámetro estimado: 19.38 mm)\n",
      "Moneda identificada: 1 cent (Diámetro estimado: 16.47 mm)\n"
     ]
    }
   ],
   "source": [
    "# Importamos las librerías necesarias\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Definimos un diccionario con los diámetros de las monedas en milímetros y sus valores\n",
    "diametros_monedas = {\n",
    "    '1 cent': 16.25,\n",
    "    '2 cent': 18.75,\n",
    "    '5 cent': 21.25,\n",
    "    '10 cent': 19.75,\n",
    "    '20 cent': 22.25,\n",
    "    '50 cent': 24.25,\n",
    "    '1 eur': 23.25,\n",
    "    '2 eur': 25.75\n",
    "}\n",
    "\n",
    "# Cargamos la imagen donde detectaremos las monedas\n",
    "imagen = cv2.imread('Monedas.jpg')\n",
    "if imagen is None:\n",
    "    print(\"Error: No se pudo cargar la imagen. Verifica la ruta del archivo.\")\n",
    "    exit()\n",
    "\n",
    "# Obtenemos las dimensiones de la pantalla (podemos ajustarlas según sea necesario)\n",
    "screen_width = 1280\n",
    "screen_height = 720\n",
    "\n",
    "# Obtenemos las dimensiones de la imagen\n",
    "height, width = imagen.shape[:2]\n",
    "\n",
    "# Calculamos el factor de escala para que la imagen quepa en la pantalla\n",
    "scale_width = screen_width / width\n",
    "scale_height = screen_height / height\n",
    "scale = min(scale_width, scale_height)\n",
    "\n",
    "# Redimensionamos la imagen respetando la relación de aspecto\n",
    "new_width = int(width * scale)\n",
    "new_height = int(height * scale)\n",
    "imagen_redimensionada = cv2.resize(imagen, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# Convertimos la imagen redimensionada a escala de grises\n",
    "imgGris = cv2.cvtColor(imagen_redimensionada, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Aplicamos un suavizado Gaussiano para reducir el ruido\n",
    "imgGris_suavizada = cv2.GaussianBlur(imgGris, (11, 11), 2)\n",
    "\n",
    "# Detectamos los círculos en la imagen usando el método HoughCircles\n",
    "monedasDetectadas = cv2.HoughCircles(\n",
    "    imgGris_suavizada,  # imagen en escala de grises suavizada\n",
    "    cv2.HOUGH_GRADIENT,  # método de detección\n",
    "    dp=1,\n",
    "    minDist=100,  # distancia mínima entre los centros de los círculos detectados\n",
    "    param1=100,  # umbral superior para el detector de bordes Canny interno\n",
    "    param2=50,  # umbral para el acumulador (cuanto más pequeño, más círculos detectados), (60 tamibén funciona)\n",
    "    minRadius=40,  # radio mínimo a detectar\n",
    "    maxRadius=150  # radio máximo a detectar\n",
    ")\n",
    "\n",
    "# Verificamos que se hayan detectado círculos y creamos la lista de monedas\n",
    "if monedasDetectadas is not None:\n",
    "    monedasDetectadas = np.int32(np.around(monedasDetectadas))\n",
    "    # Creamos una lista para almacenar las monedas detectadas\n",
    "    coins = []\n",
    "    for i in monedasDetectadas[0, :]:\n",
    "        coin = {\n",
    "            'center': (i[0], i[1]),\n",
    "            'radius': i[2],\n",
    "            'value': None,  # Valor asignado o calculado\n",
    "            'diameter_px': i[2] * 2  # Diámetro en píxeles\n",
    "        }\n",
    "        coins.append(coin)\n",
    "else:\n",
    "    print(\"No se detectaron monedas.\")\n",
    "    monedasDetectadas = np.array([])\n",
    "    coins = []\n",
    "\n",
    "# Inicializamos la relación píxeles/mm como None\n",
    "pixel_mm_ratio = None\n",
    "\n",
    "# Función para manejar los clics del ratón\n",
    "def onclick(event, x, y, flags, param):\n",
    "    global pixel_mm_ratio\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        # Verificamos si se ha hecho clic sobre alguna moneda\n",
    "        if coins:\n",
    "            for coin in coins:\n",
    "                dx = x - coin['center'][0]\n",
    "                dy = y - coin['center'][1]\n",
    "                distancia_cuadrada = dx ** 2 + dy ** 2\n",
    "                if distancia_cuadrada <= coin['radius'] ** 2:\n",
    "                    # Si se ha hecho clic sobre una moneda, la tomamos como la moneda de 1 EUR\n",
    "                    print(\"Moneda seleccionada como referencia (1 EUR)\")\n",
    "                    diametro_real_mm = diametros_monedas['1 eur']\n",
    "                    diametro_pixel = coin['diameter_px']\n",
    "                    pixel_mm_ratio = diametro_pixel / diametro_real_mm\n",
    "                    print(f\"Relación píxeles/mm calculada: {pixel_mm_ratio:.4f}\")\n",
    "                    # Identificamos las demás monedas\n",
    "                    identificar_monedas()\n",
    "                    break\n",
    "\n",
    "# Función para identificar las monedas restantes usando la relación píxeles/mm\n",
    "def identificar_monedas():\n",
    "    global coins, pixel_mm_ratio, diametros_monedas\n",
    "\n",
    "    # Creamos una lista de diámetros reales y sus valores\n",
    "    diametros_reales = np.array(list(diametros_monedas.values()))\n",
    "    valores_monedas = list(diametros_monedas.keys())\n",
    "\n",
    "    for coin in coins:\n",
    "        if coin['value'] is None:\n",
    "            # Calculamos el diámetro en milímetros usando la relación píxeles/mm\n",
    "            diametro_mm = coin['diameter_px'] / pixel_mm_ratio\n",
    "            # Encontramos el diámetro real más cercano\n",
    "            idx = (np.abs(diametros_reales - diametro_mm)).argmin()\n",
    "            coin['value'] = valores_monedas[idx]\n",
    "            print(f\"Moneda identificada: {coin['value']} (Diámetro estimado: {diametro_mm:.2f} mm)\")\n",
    "\n",
    "# Mostramos la imagen y conectamos el evento de clic\n",
    "cv2.namedWindow('Monedas', cv2.WINDOW_AUTOSIZE)\n",
    "cv2.setMouseCallback('Monedas', onclick)\n",
    "\n",
    "while True:\n",
    "    # Dibujamos los círculos detectados en la imagen redimensionada\n",
    "    imagen_circulos = imagen_redimensionada.copy()\n",
    "    for coin in coins:\n",
    "        centro = coin['center']\n",
    "        radio = coin['radius']\n",
    "        cv2.circle(imagen_circulos, centro, radio, (0, 0, 255), 2)\n",
    "\n",
    "        # Si la moneda tiene un valor asignado, lo mostramos\n",
    "        if coin['value'] is not None:\n",
    "            # Dibujamos el valor de la moneda sobre ella\n",
    "            text = coin['value']\n",
    "            # Calculamos la posición del texto\n",
    "            text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]\n",
    "            text_x = int(centro[0] - text_size[0] / 2)\n",
    "            text_y = int(centro[1] + text_size[1] / 2)\n",
    "            cv2.putText(imagen_circulos, text, (text_x, text_y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "    # Si ya hemos calculado la relación píxeles/mm, mostramos la suma total\n",
    "    if pixel_mm_ratio is not None:\n",
    "        # Calculamos la suma total de dinero\n",
    "        total_sum = 0\n",
    "        for coin in coins:\n",
    "            if coin['value'] is not None:\n",
    "                value_str = coin['value']\n",
    "                if 'cent' in value_str:\n",
    "                    # Convertimos a euros\n",
    "                    value = int(value_str.split(' ')[0]) / 100\n",
    "                elif 'eur' in value_str:\n",
    "                    value = float(value_str.split(' ')[0])\n",
    "                else:\n",
    "                    value = 0  # O manejamos el error\n",
    "                total_sum += value\n",
    "\n",
    "        # Mostramos la suma total en la parte superior con fondo negro semitransparente y letras blancas\n",
    "        overlay = imagen_circulos.copy()\n",
    "        cv2.rectangle(overlay, (0, 0), (imagen_circulos.shape[1], 50), (0, 0, 0), -1)\n",
    "        alpha = 0.5  # Factor de transparencia\n",
    "\n",
    "        # Superponemos el rectángulo semitransparente sobre la imagen\n",
    "        cv2.addWeighted(overlay, alpha, imagen_circulos, 1 - alpha, 0, imagen_circulos)\n",
    "\n",
    "        # Ponemos el texto de la suma total\n",
    "        total_text = f\"Dinero total: {total_sum:.2f}eur\"\n",
    "        cv2.putText(imagen_circulos, total_text, (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    # Mostramos la imagen con los círculos y valores detectados\n",
    "    cv2.imshow('Monedas', imagen_circulos)\n",
    "\n",
    "    # Salimos con la tecla 'Esc' (código ASCII 27)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# Cerramos todas las ventanas al finalizar\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mundo real es muy variado, las imágenes no siempre se capturan con unas condiciones de iluminación tan buenas o controladas. Ejemplo con aplicación de variantes de umbralizados ofrecidas por OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carga imagen directamente en grises\n",
    "imgorig = cv2.imread('MPs.jpg', cv2.IMREAD_GRAYSCALE) \n",
    "\n",
    "img = cv2.GaussianBlur(imgorig,(5,5),0)\n",
    "\n",
    "#Umbralizados\n",
    "ret,imth1 = cv2.threshold(img,150,255,cv2.THRESH_BINARY_INV)\n",
    "thotsu,imth2 = cv2.threshold(img,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "print('Umbral escogido ', thotsu)\n",
    "imth3 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "            cv2.THRESH_BINARY,11,2)\n",
    "imth4 = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "            cv2.THRESH_BINARY,11,2)\n",
    " \n",
    "titles = ['Original', 'Fijo','Otsu th='+str(int(thotsu)),\n",
    "            'Adaptivo promedio', 'Adaptivo Gaussiano']\n",
    "images = [img, imth1, imth2, 255 - imth3, 255 - imth4]\n",
    " \n",
    "for i in range(5):\n",
    "    plt.subplot(2,5,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i], fontsize=7)\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "    #Obtiene únicamente los contornos externos\n",
    "    if i>0:\n",
    "        res,imth = cv2.threshold(images[i],120,255,cv2.THRESH_BINARY)\n",
    "        contornos, hierarchy= cv2.findContours(imth, \n",
    "        cv2.RETR_EXTERNAL , \n",
    "        cv2.CHAIN_APPROX_SIMPLE)  \n",
    "        img_cont = np.zeros(img.shape)\n",
    "        cv2.drawContours(img_cont, contornos, -1, (255,255,255), -1)  \n",
    "        plt.subplot(2,5,i+6),plt.imshow(img_cont,'gray')\n",
    "        plt.xticks([]),plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasificación de microplásticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos tres subimágenes de cada uno de los tres tipos considerados (el alquitrán no es microplástico)\n",
    "imgF = cv2.imread('FRA.png') \n",
    "imgP = cv2.imread('PEL.png') \n",
    "imgT = cv2.imread('TAR.png') \n",
    "\n",
    "#Mostramos\n",
    "plt.subplot(131)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(imgF) \n",
    "plt.title('Fragmentos')\n",
    "plt.subplot(132)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(imgP) \n",
    "plt.title('Pellet')\n",
    "plt.subplot(133)\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(imgT) \n",
    "plt.title('Alquitrán')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de la siguiente tarea, descrita más abajo, es desarrollar tu propio clasificador basado únicamente en heurísticas desde características geométricas y/o de apariencia, para distinguir en las imágenes completas, las partículas de cada tipo, debiendo mostrar la bondad del clasificador haciendo uso de métricas para ello. La siguiente celda obtiene varias métricas para un conjunto de datos imaginario (y con etiquetas aleatorias). Si bien las trataremos con más detalle en teoría, muestro un repertorio de ellas, dando más peso a la matriz de confusión. La ejecución de la celda requiere instalar el paquete scikit-learn.\n",
    "\n",
    "¿Qué es una matriz de confusión?\n",
    "Se utiliza para mostrar el comportamiento de un clasificador para las distintas clases conocidas, se relacionan las etiquetas de las muestras anotadas frente a las predichas por el clasificador. Se busca una matriz diagonal, pero la perfección es infrecuente.\n",
    "\n",
    "El siguiente ejemplo, muestra el modo de obtener la matriz de confusión para un hipotético problema con cuatro clases, y valores de anotación (variable y) y predicción (variable y_pred) obtenidos de forma aleatoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "\n",
    "# Numero de muestras\n",
    "n = 100  \n",
    "nclases = 4\n",
    "\n",
    "# A falta de clasificador y conjunto de datos, creamos anotaciones y predicciones de forma aleatoria\n",
    "# Vector aleatorio con etiquetas anotadas\n",
    "y = [random.randint(0, nclases - 1) for _ in range(n)]\n",
    "print('Anotaciones ' , y)\n",
    "\n",
    "# Vector aleatorio con etiquetas predichas por un supuesto clasificador\n",
    "y_pred = [random.randint(0, nclases - 1) for _ in range(n)]\n",
    "print('Predicciones ' , y_pred)\n",
    "\n",
    "print('¿Cómo de bien encajan anotación y predicción?')\n",
    "\n",
    "#Cálculo de métricas\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "#Para más de una clase se define la forma de promediar\n",
    "precision = precision_score(y, y_pred,average='weighted')\n",
    "recall = recall_score(y, y_pred,average='weighted')\n",
    "f1score = f1_score(y, y_pred,average='weighted')\n",
    "\n",
    "print(f\"Accuracy (TP/(n))= {accuracy}\")\n",
    "print(f\"Precision (TP/(TP+FP)) = {precision}\")\n",
    "print(f\"Recall (TP/(TP+FN)) = {recall}\")\n",
    "print(f\"F1 Score (2*(precision*recall)/(precision+recall)) = {f1score}\")\n",
    "\n",
    "\n",
    "conf_matrix = confusion_matrix(y, y_pred)\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.set(font_scale = 1.75)#tamaños tipografía\n",
    "sns.set(font_scale = 3.0)\n",
    "\n",
    "ax = sns.heatmap(\n",
    "        conf_matrix, # confusion matrix 2D array \n",
    "        annot=True, # Muestra números en las celdas\n",
    "        fmt='d', # valores enteros\n",
    "        cbar=False, # sin barra de colores\n",
    "        cmap='flag', # mapa de colores\n",
    "        #vmax=175 # contraste de color\n",
    "    )\n",
    "\n",
    "#Etiquetas matriz de confusión\n",
    "label_font = {'size':'25'}\n",
    "ax.set_xlabel(\"Predicha\", labelpad=-0.75, fontdict=label_font)\n",
    "ax.set_ylabel(\"Real/Anotado\", labelpad=20, fontdict=label_font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAREA: Las tres imágenes cargadas en la celda inicial, han sido extraidas de las imágenes de mayor tamaño presentes en la carpeta. La tarea consiste en extraer características (geométricas y/o visuales) e identificar patrones que permitan distinguir las partículas de cada una de las tres clases, evaluando los aciertos y fallos con las imágenes completas considerando las métricas mostradas y la matriz de confusión. La matriz de confusión, muestra para cada clase el número de muestras que se clasifican correctamente de dicha clase, y el número de muestras que se clasifican incorrectamente por cada una de las otras dos clases.\n",
    "\n",
    "En el trabajo [SMACC: A System for Microplastics Automatic Counting and Classification](https://doi.org/10.1109/ACCESS.2020.2970498), las características geométricas utilizadas fueron:\n",
    "\n",
    "- Área en píxeles\n",
    "- Perímetro en píxeles\n",
    "- Compacidad (relación entre el cuadrado del perímetro y el área de la partícula)\n",
    "- Relación del área de la partícula con la del contenedor\n",
    "- Relación del ancho y el alto del contenedor\n",
    "- Relación entre los ejes de la elipse ajustada\n",
    "- Definido el centroide, relación entre las distancias menor y mayor al contorno\n",
    "\n",
    "Si no se quedan satisfechos con la segmentación obtenida, es el mundo real, también en el README comento técnicas recientes de segmentación, que podrían despertar su curiosidad."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VC_P1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
